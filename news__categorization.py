import nltk
from gensim import corpora
from gensim.models import LdaModel
import spacy
import pandas as pd

# Download stopwords if not already done
nltk.download('stopwords')

# Load the spaCy model
nlp = spacy.load('en_core_web_sm')

# Preprocess the text: lemmatize and remove stopwords/punctuation
def preprocess(text):
    doc = nlp(text)
    tokens = [token.lemma_.lower() for token in doc if not token.is_stop and not token.is_punct]
    return tokens

# Map common keywords to predefined categories (lowercase and lemmatized)
category_keywords = {
    'politics': ['government', 'election', 'policy', 'politic', 'president', 'minister', 
                 'senator', 'congress', 'vote', 'parliament', 'diplomacy', 'law', 'legislation', 
                 'campaign', 'governor', 'prime minister', 'cabinet'],
                 
    'technology': ['technology', 'tech', 'innovation', 'software', 'internet', 'ai', 'artificial intelligence',
                   'cloud', 'blockchain', 'robotics', 'gadget', 'mobile', 'programming', 'developer', 
                   'cybersecurity', 'digital', 'automation', 'machine learning', 'startup', 'hardware'],
                   
    'entertainment': ['movie', 'music', 'film', 'actor', 'show', 'entertainment', 'singer', 'actress', 
                      'concert', 'album', 'festival', 'theater', 'director', 'celebrity', 'television', 
                      'broadway', 'award', 'reality show', 'media', 'hollywood', 'bollywood'],
                      
    'sports': ['game', 'sport', 'team', 'match', 'player', 'champion', 'tournament', 'league', 'coach', 
               'athlete', 'score', 'goal', 'olympics', 'cricket', 'football', 'basketball', 'tennis', 
               'baseball', 'soccer', 'world cup', 'stadium', 'medal'],
               
    'business': ['business', 'market', 'stock', 'trade', 'economy', 'finance', 'investment', 'startup', 
                 'revenue', 'profit', 'shares', 'bank', 'entrepreneur', 'merger', 'acquisition', 'currency', 
                 'capital', 'company', 'tax', 'industry', 'commerce', 'corporation', 'venture', 'funding'],
                 
    'health': ['health', 'doctor', 'hospital', 'medicine', 'wellness', 'nurse', 'surgery', 'vaccine', 
               'disease', 'treatment', 'covid', 'pandemic', 'mental health', 'clinic', 'diagnosis', 
               'pharmacy', 'nutrition', 'fitness', 'insurance', 'therapy', 'public health'],
               
    'science': ['science', 'research', 'discovery', 'experiment', 'study', 'space', 'biology', 
                'chemistry', 'physics', 'scientist', 'genetics', 'astronomy', 'universe', 'laboratory', 
                'evolution', 'theory', 'data', 'analysis', 'microscope', 'quantum', 'hypothesis'],
                
    'environment': ['environment', 'climate', 'earth', 'pollution', 'green', 'nature', 'sustainability', 
                    'wildlife', 'global warming', 'conservation', 'ecosystem', 'renewable', 'energy', 
                    'recycling', 'carbon', 'deforestation', 'habitat', 'ocean', 'biodiversity', 'emissions']
}


# Function to categorize based on keywords directly from the preprocessed text
def categorize_by_keywords(preprocessed_text):
    for category, keyword_list in category_keywords.items():
        if any(keyword in preprocessed_text for keyword in keyword_list):
            return category
    return "other"  # No match found

# Load the CSV file
df = pd.read_csv('news_art.csv')

# Process each article in the CSV
categories = []
for summary in df['summary']:
    # Preprocess the text
    preprocessed_article = preprocess(summary)
    
    # First, try categorizing by keyword matching
    category = categorize_by_keywords(preprocessed_article)
    
    # If no category is found by keyword matching, fall back to LDA model
    if category == "other":
        # Prepare data for LDA model
        dictionary = corpora.Dictionary([preprocessed_article])
        doc_term_matrix = [dictionary.doc2bow(preprocessed_article)]
        
        # Build the LDA model
        lda_model = LdaModel(doc_term_matrix, num_topics=5, id2word=dictionary)
        
        # Get the topics generated by the LDA model
        topics = lda_model.print_topics(num_topics=5, num_words=5)
        
        # Extract keywords from the topics
        lda_keywords = [word.split('*')[1].replace('"', '').strip() for i, ctgy in topics for word in ctgy.split(' + ')]
        
        # Categorize the article based on LDA keywords
        category = categorize_by_keywords(lda_keywords)
    
    # Append the category to the list
    categories.append(category)

# Add the categories back to the DataFrame and save to CSV
df['category'] = categories
df.to_csv('news_art.csv', index=False)
print("CSV updated with predicted categories.")
